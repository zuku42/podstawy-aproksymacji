{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "14d4b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5391f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "train_data_dir = 'processed_data/train'\n",
    "validation_data_dir = 'processed_data/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d2de8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_files(directory):\n",
    "    count = 0\n",
    "    for _, _, files in os.walk(directory):\n",
    "        count += len(files)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e0f01aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_samples = get_n_files(train_data_dir)\n",
    "n_validation_samples = get_n_files(validation_data_dir)\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1fae1193",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bdbf8a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "74e72e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 381 images belonging to 2 classes.\n",
      "Found 94 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 35s 3s/step - loss: 1.4211 - accuracy: 0.5272 - val_loss: 0.6874 - val_accuracy: 0.7344\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 33s 3s/step - loss: 0.6438 - accuracy: 0.6562 - val_loss: 0.5562 - val_accuracy: 0.7903\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.5899 - accuracy: 0.7020 - val_loss: 0.5427 - val_accuracy: 0.7742\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 33s 3s/step - loss: 0.5590 - accuracy: 0.7197 - val_loss: 0.6155 - val_accuracy: 0.7188\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 33s 3s/step - loss: 0.4914 - accuracy: 0.7822 - val_loss: 0.5429 - val_accuracy: 0.7258\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.4442 - accuracy: 0.8052 - val_loss: 0.7181 - val_accuracy: 0.7419\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 33s 3s/step - loss: 0.4100 - accuracy: 0.7937 - val_loss: 0.5917 - val_accuracy: 0.7188\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 34s 3s/step - loss: 0.4481 - accuracy: 0.8125 - val_loss: 0.3120 - val_accuracy: 0.8065\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.3647 - accuracy: 0.8424 - val_loss: 0.5954 - val_accuracy: 0.6452\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.2824 - accuracy: 0.8797 - val_loss: 0.5610 - val_accuracy: 0.7344\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 33s 3s/step - loss: 0.2630 - accuracy: 0.8968 - val_loss: 0.8892 - val_accuracy: 0.7258\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 35s 3s/step - loss: 0.2404 - accuracy: 0.9198 - val_loss: 0.5847 - val_accuracy: 0.8226\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 34s 3s/step - loss: 0.1822 - accuracy: 0.9398 - val_loss: 0.8598 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.1842 - accuracy: 0.9284 - val_loss: 1.2262 - val_accuracy: 0.7258\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.1669 - accuracy: 0.9341 - val_loss: 0.2574 - val_accuracy: 0.8548\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.1802 - accuracy: 0.9427 - val_loss: 1.2323 - val_accuracy: 0.7188\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 33s 3s/step - loss: 0.1623 - accuracy: 0.9398 - val_loss: 1.7183 - val_accuracy: 0.7581\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 33s 3s/step - loss: 0.1456 - accuracy: 0.9398 - val_loss: 0.4460 - val_accuracy: 0.7581\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 35s 3s/step - loss: 0.1173 - accuracy: 0.9631 - val_loss: 1.2607 - val_accuracy: 0.6719\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 34s 3s/step - loss: 0.1243 - accuracy: 0.9509 - val_loss: 1.1788 - val_accuracy: 0.7742\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1. / 255, shear_range=0.2, zoom_range=0.1, horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_width, img_height),\n",
    "                                                    batch_size=batch_size, class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir, target_size=(img_width, img_height),\n",
    "                                                        batch_size=batch_size, class_mode='binary')\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=n_train_samples // batch_size, epochs=epochs,\n",
    "                              validation_data=validation_generator, validation_steps=n_validation_samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3c7c5cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "n_damaged = 0\n",
    "n_undamaged = 0\n",
    "\n",
    "# load images from the validation directory and count the number\n",
    "# of instances belonging to each of the classes\n",
    "for directory in ['undamaged', 'damaged']:\n",
    "    full_img_paths = glob.glob(os.path.join(validation_data_dir, directory, '*'))\n",
    "    for img_path in full_img_paths:\n",
    "        try:\n",
    "            image = io.imread(img_path)\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            images.append(image.reshape(1, 224, 224, 3))\n",
    "            n_damaged += int('undamaged' not in directory)\n",
    "            n_undamaged += int('undamaged' in directory)\n",
    "        except ValueError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7617b447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'damaged': 0, 'undamaged': 1}\n"
     ]
    }
   ],
   "source": [
    "# check which class is represented by 1\n",
    "class_dict = validation_generator.class_indices\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b3c6706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector of true classes in the validation set\n",
    "y_test = n_undamaged * [class_dict['undamaged']] + n_damaged * [class_dict['damaged']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "548c6bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (random model):  0.4787234042553192\n",
      "Accuracy (model always predicting the most prevalent class):  0.5212765957446809\n"
     ]
    }
   ],
   "source": [
    "# baseline model - random prediction\n",
    "y_pred_random = np.random.randint(0, 1, len(images))\n",
    "\n",
    "# baseline model - always predicts most prevalent class\n",
    "y_pred_mono = len(images) * [max(set(y_test), key=y_test.count)]\n",
    "\n",
    "# baseline accuracies\n",
    "print('Accuracy (random model): ', accuracy_score(y_test, y_pred_random))\n",
    "print('Accuracy (model always predicting the most prevalent class): ', accuracy_score(y_test, y_pred_mono))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c3fa0695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions using trained model\n",
    "images = np.vstack(images)\n",
    "images = images / 255.0\n",
    "y_pred = model.predict_classes(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e0e6e63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy:  0.7553191489361702\n",
      "[[33 12]\n",
      " [11 38]]\n"
     ]
    }
   ],
   "source": [
    "print('Model accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
